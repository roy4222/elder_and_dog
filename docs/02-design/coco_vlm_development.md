# COCO VLM æ•´åˆé–‹ç™¼æ–‡ä»¶ï¼ˆPlan A ä¸»åŠ›æ–¹æ¡ˆï¼‰

**ç‰ˆæœ¬**ï¼šv1.0
**å»ºç«‹æ—¥æœŸ**ï¼š2025/11/20
**æœ€å¾Œæ›´æ–°**ï¼š2025/11/20
**ç‹€æ…‹**ï¼šğŸŸ¢ ä¸»åŠ›é–‹ç™¼æ–¹æ¡ˆï¼ˆæ ¹æ“š 2025/11/19 æœƒè­°æ±ºè­°ï¼‰

---

## ç›®éŒ„

1. [æ–¹æ¡ˆæ¦‚è¿°](#æ–¹æ¡ˆæ¦‚è¿°)
2. [æŠ€è¡“æ¶æ§‹](#æŠ€è¡“æ¶æ§‹)
3. [ç’°å¢ƒå»ºç½®](#ç’°å¢ƒå»ºç½®)
4. [COCO æ¨¡å‹æ•´åˆ](#coco-æ¨¡å‹æ•´åˆ)
5. [ROS2 ç¯€é»å¯¦ä½œ](#ros2-ç¯€é»å¯¦ä½œ)
6. [æ¸¬è©¦èˆ‡é©—è­‰](#æ¸¬è©¦èˆ‡é©—è­‰)
7. [æ•ˆèƒ½å„ªåŒ–](#æ•ˆèƒ½å„ªåŒ–)
8. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

---

## æ–¹æ¡ˆæ¦‚è¿°

### ç‚ºä»€éº¼é¸æ“‡ COCOï¼Ÿ

æ ¹æ“š **2025/11/19 æœƒè­°æ±ºè­°**ï¼ŒCOCO æ¨¡å‹è¢«é¸ç‚ºä¸»åŠ› VLM æ–¹æ¡ˆï¼ŒåŸå› å¦‚ä¸‹ï¼š

#### âœ… å„ªå‹¢

1. **å®Œå…¨è‡ªä¸»æ§åˆ¶**
   - ç„¡éœ€ä¾è³´å¤–éƒ¨ APIï¼ˆGemini å¯©æ ¸ä¸­ï¼Œä¸ç¢ºå®šæ€§é«˜ï¼‰
   - ä¸å—ç¶²è·¯é™åˆ¶ï¼Œé©åˆå¯¦æ©Ÿå±•ç¤ºï¼ˆ12/17 ç™¼è¡¨ï¼‰
   - ç„¡ API é¡åº¦é™åˆ¶

2. **ç¡¬é«”è³‡æºå……è¶³**
   - Quadro RTX 8000 48GB å®Œå…¨æ”¯æ´è¨“ç·´èˆ‡æ¨è«–
   - æœ¬åœ° GPU æ¨è«–å»¶é²å¯æ§ï¼ˆ< 0.5 ç§’ï¼‰

3. **å·²æœ‰åŸºç¤**
   - COCO è³‡æ–™é›†åŒ…å« 80 ç¨®å¸¸è¦‹ç‰©å“é¡åˆ¥
   - Go2 SDK æ–‡ä»¶ä¸­å·²æåŠæ”¯æ´ COCO Detector
   - PyTorch ç”Ÿæ…‹ç³»çµ±æˆç†Ÿ

4. **é©åˆ 12/17 ç™¼è¡¨**
   - å¯¦æ©Ÿå±•ç¤ºç„¡éœ€ç¶²è·¯
   - å¯é›¢ç·šé‹è¡Œ
   - æ•ˆæœå¯é æ¸¬ã€å¯æ§

#### âš ï¸ åŠ£å‹¢èˆ‡æ‡‰å°

| åŠ£å‹¢ | å½±éŸ¿ | æ‡‰å°æ–¹æ¡ˆ |
|------|------|---------|
| éœ€è¦æ¨™è¨»è³‡æ–™ | è‹¥è¦å¾®èª¿æ¨¡å‹ | éšæ®µä¸€ä½¿ç”¨é è¨“ç·´æ¬Šé‡å³å¯ |
| é–‹ç™¼æ™‚é–“è¼ƒé•· | W6-W7 æ™‚ç¨‹ç·Šè¿« | ä½¿ç”¨ç¾æˆ torchvision æ¨¡å‹ |
| è­˜åˆ¥é¡åˆ¥å›ºå®š | åƒ…é™ COCO 80 é¡ | æ¶µè“‹å¸¸è¦‹ç‰©å“ï¼ˆçœ¼é¡ã€é™æ§å™¨ã€é‘°åŒ™ç­‰ï¼‰ |

### å‚™æ¡ˆæ–¹æ¡ˆ

- **Plan B**ï¼šGemini Robotics APIï¼ˆå¯©æ ¸ä¸­ï¼Œè¦‹ `gemini_vlm_backup.md`ï¼‰
- **Plan C**ï¼šOpenAI/Claude Vision APIï¼ˆæœ€å¾Œæ‰‹æ®µï¼‰

---

## æŠ€è¡“æ¶æ§‹

### ç³»çµ±æ¶æ§‹åœ–

```mermaid
graph TD
    A[Go2 Robot Camera] -->|/camera/image_raw| B[COCO Detector Node]
    B -->|PyTorch Inference| C[MobileNet SSD v2]
    C -->|Detections| D[Detection2DArray Converter]
    D -->|/detected_objects| E[Coordinate Transformer]

    F[COCO Classes JSON] -.->|80 é¡åˆ¥æ˜ å°„| D
    G[Quadro RTX 8000] -.->|GPU åŠ é€Ÿ| C

    style B fill:#4CAF50,stroke:#2E7D32,color:#fff
    style C fill:#2196F3,stroke:#1565C0,color:#fff
    style G fill:#FF9800,stroke:#E65100,color:#fff
```

### è³‡æ–™æµå‘

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Go2 Camera     â”‚
â”‚  (720p/1080p)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ sensor_msgs/Image
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  COCO Detector Node         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 1. Image Preprocessingâ”‚   â”‚
â”‚  â”‚    - Resize to 640x640â”‚   â”‚
â”‚  â”‚    - Normalize        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚              â–¼              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 2. PyTorch Inference  â”‚   â”‚
â”‚  â”‚    - MobileNet SSD v2 â”‚   â”‚
â”‚  â”‚    - Confidence > 0.5 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚              â–¼              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 3. NMS Filtering      â”‚   â”‚
â”‚  â”‚    - IoU threshold    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚              â–¼              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 4. Detection2DArray   â”‚   â”‚
â”‚  â”‚    - Bounding boxes   â”‚   â”‚
â”‚  â”‚    - Class labels (ä¸­æ–‡)â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ vision_msgs/Detection2DArray
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Coordinate          â”‚
â”‚ Transformer Node    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ç’°å¢ƒå»ºç½®

### ç¡¬é«”éœ€æ±‚

| çµ„ä»¶ | æœ€ä½éœ€æ±‚ | æ¨è–¦é…ç½® | æœ¬å°ˆæ¡ˆé…ç½® |
|------|---------|---------|-----------|
| GPU | GTX 1060 (6GB) | RTX 3060 (12GB) | **Quadro RTX 8000 (48GB)** âœ… |
| RAM | 8GB | 16GB | å……è¶³ |
| å„²å­˜ç©ºé–“ | 10GB | 20GB | å……è¶³ |

### è»Ÿé«”ç’°å¢ƒ

**ä½œæ¥­ç³»çµ±**ï¼šUbuntu 22.04 LTS
**Python**ï¼š3.10
**ROS2**ï¼šHumble
**CUDA**ï¼š11.8+ (èˆ‡ PyTorch ç‰ˆæœ¬å°æ‡‰)

### ä¾è³´å®‰è£

#### 1. å®‰è£ PyTorch èˆ‡ TorchVision

```bash
# æª¢æŸ¥ CUDA ç‰ˆæœ¬
nvidia-smi

# å®‰è£ PyTorch (CUDA 11.8 ç¯„ä¾‹)
uv pip install torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu118

# é©—è­‰å®‰è£
python3 -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA Available: {torch.cuda.is_available()}')"
```

**é æœŸè¼¸å‡º**ï¼š
```
PyTorch: 2.1.0+cu118
CUDA Available: True
```

#### 2. å®‰è£ ROS2 ä¾è³´

```bash
# å®‰è£ vision_msgs
sudo apt-get install ros-humble-vision-msgs

# æˆ–ä½¿ç”¨ rosdep
cd /Users/lubaiyu/elder_and_dog
rosdep install --from-paths src --ignore-src -r -y
```

#### 3. å®‰è£å…¶ä»–ä¾è³´

```bash
# åˆ‡æ›åˆ°å°ˆæ¡ˆç›®éŒ„
cd /Users/lubaiyu/elder_and_dog

# å»ºç«‹ COCO VLM å°ˆç”¨ä¾è³´æª”
cat > src/vision_vlm/requirements-coco.txt <<EOF
torch==2.1.0
torchvision==0.16.0
numpy==1.24.4
opencv-python==4.8.1.78
Pillow==10.1.0
EOF

# å®‰è£ä¾è³´ï¼ˆä½¿ç”¨ uvï¼‰
uv pip install -r src/vision_vlm/requirements-coco.txt
```

---

## COCO æ¨¡å‹æ•´åˆ

### COCO 80 é¡åˆ¥æ¸…å–®

COCO è³‡æ–™é›†åŒ…å« 80 ç¨®å¸¸è¦‹ç‰©å“ï¼Œæ¶µè“‹è€äººå°‹ç‰©çš„ä¸»è¦å ´æ™¯ï¼š

<details>
<summary>é»æ“Šå±•é–‹å®Œæ•´é¡åˆ¥æ¸…å–®ï¼ˆç¹é«”ä¸­æ–‡æ˜ å°„ï¼‰</summary>

```python
COCO_CLASSES = {
    1: "äºº", 2: "è…³è¸è»Š", 3: "æ±½è»Š", 4: "æ©Ÿè»Š", 5: "é£›æ©Ÿ",
    6: "å…¬è»Š", 7: "ç«è»Š", 8: "å¡è»Š", 9: "èˆ¹", 10: "ç´…ç¶ ç‡ˆ",
    11: "æ¶ˆé˜²æ “", 13: "åœæ­¢æ¨™èªŒ", 14: "åœè»Šæ”¶è²»è¡¨", 15: "é•·æ¤…", 16: "é³¥",
    17: "è²“", 18: "ç‹—", 19: "é¦¬", 20: "ç¾Š", 21: "ç‰›",
    22: "å¤§è±¡", 23: "ç†Š", 24: "æ–‘é¦¬", 25: "é•·é ¸é¹¿", 27: "èƒŒåŒ…",
    28: "é›¨å‚˜", 31: "æ‰‹æåŒ…", 32: "é ˜å¸¶", 33: "è¡Œæç®±", 34: "é£›ç›¤",
    35: "æ»‘é›ªæ¿", 36: "æ»‘é›ªæ¿", 37: "é‹å‹•çƒ", 38: "é¢¨ç®", 39: "æ£’çƒæ£’",
    40: "æ£’çƒæ‰‹å¥—", 41: "æ»‘æ¿", 42: "è¡æµªæ¿", 43: "ç¶²çƒæ‹", 44: "ç“¶å­",
    45: "é…’æ¯", 46: "æ¯å­", 47: "å‰å­", 48: "åˆ€", 49: "æ¹¯åŒ™",
    50: "ç¢—", 51: "é¦™è•‰", 52: "è˜‹æœ", 53: "ä¸‰æ˜æ²»", 54: "æ©˜å­",
    55: "èŠ±æ¤°èœ", 56: "ç´…è˜¿è””", 57: "ç†±ç‹—", 58: "æŠ«è–©", 59: "ç”œç”œåœˆ",
    60: "è›‹ç³•", 61: "æ¤…å­", 62: "æ²™ç™¼", 63: "ç›†æ ½æ¤ç‰©", 64: "åºŠ",
    67: "é¤æ¡Œ", 70: "é¦¬æ¡¶", 72: "é›»è¦–", 73: "ç­†è¨˜å‹é›»è…¦", 74: "æ»‘é¼ ",
    75: "é™æ§å™¨", 76: "éµç›¤", 77: "æ‰‹æ©Ÿ", 78: "å¾®æ³¢çˆ", 79: "çƒ¤ç®±",
    80: "çƒ¤éºµåŒ…æ©Ÿ", 81: "æ°´æ§½", 82: "å†°ç®±", 84: "æ›¸", 85: "æ™‚é˜",
    86: "èŠ±ç“¶", 87: "å‰ªåˆ€", 88: "æ³°è¿ªç†Š", 89: "å¹é¢¨æ©Ÿ", 90: "ç‰™åˆ·"
}

# è€äººå°‹ç‰©é«˜é »ç‰©å“ï¼ˆæ ¹æ“šéœ€æ±‚æ–‡ä»¶ï¼‰
HIGH_PRIORITY_OBJECTS = [
    "é™æ§å™¨",  # ID: 75
    "æ‰‹æ©Ÿ",    # ID: 77
    "çœ¼é¡",    # éœ€é¡å¤–è¨“ç·´æˆ–ä½¿ç”¨ Gemini å‚™æ¡ˆ
    "é‘°åŒ™",    # éœ€é¡å¤–è¨“ç·´æˆ–ä½¿ç”¨ Gemini å‚™æ¡ˆ
    "è—¥ç“¶",    # "ç“¶å­" ID: 44 å¯éƒ¨åˆ†æ¶µè“‹
    "æ¯å­",    # ID: 46
    "æ›¸",      # ID: 84
]
```

**æ³¨æ„**ï¼šçœ¼é¡ã€é‘°åŒ™ä¸åœ¨ COCO 80 é¡ä¸­ï¼Œéœ€è¦ï¼š
1. ä½¿ç”¨ Gemini API ä½œç‚ºè£œå……ï¼ˆPlan Bï¼‰
2. æˆ–é€²è¡Œ COCO æ¨¡å‹å¾®èª¿ï¼ˆç¬¬äºŒéšæ®µï¼‰

</details>

### æ¨¡å‹é¸æ“‡

#### æ¨è–¦ï¼šMobileNet SSD v2

```python
import torch
from torchvision.models.detection import ssdlite320_mobilenet_v3_large
from torchvision.models.detection import SSDLite320_MobileNet_V3_Large_Weights

# è¼‰å…¥é è¨“ç·´æ¨¡å‹
weights = SSDLite320_MobileNet_V3_Large_Weights.COCO_V1
model = ssdlite320_mobilenet_v3_large(weights=weights)
model.eval()

# ç§»è‡³ GPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

print(f"æ¨¡å‹è¼‰å…¥æˆåŠŸï¼Œé‹è¡Œæ–¼: {device}")
```

**é¸æ“‡ç†ç”±**ï¼š
- âœ… è¼•é‡ç´šï¼ˆç´„ 3.5M åƒæ•¸ï¼‰
- âœ… æ¨è«–é€Ÿåº¦å¿«ï¼ˆ~30 FPS @ RTX 8000ï¼‰
- âœ… é è¨“ç·´æ–¼ COCO è³‡æ–™é›†
- âœ… TorchVision å®˜æ–¹æ”¯æ´

#### æ›¿ä»£æ–¹æ¡ˆï¼šFaster R-CNN

```python
from torchvision.models.detection import fasterrcnn_resnet50_fpn
from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights

weights = FasterRCNN_ResNet50_FPN_Weights.COCO_V1
model = fasterrcnn_resnet50_fpn(weights=weights)
model.eval()
```

**å„ªé»**ï¼šæº–ç¢ºç‡æ›´é«˜
**ç¼ºé»**ï¼šé€Ÿåº¦è¼ƒæ…¢ï¼ˆ~15 FPSï¼‰ï¼Œåƒæ•¸é‡å¤§ï¼ˆ~42Mï¼‰

**å»ºè­°**ï¼šéšæ®µä¸€ä½¿ç”¨ MobileNet SSDï¼Œè‹¥æº–ç¢ºç‡ä¸è¶³å†å‡ç´šã€‚

---

## ROS2 ç¯€é»å¯¦ä½œ

### å¥—ä»¶çµæ§‹

```bash
src/vision_vlm/
â”œâ”€â”€ vision_vlm/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ coco_detector_node.py          # ä¸»ç¯€é»
â”‚   â”œâ”€â”€ coco_classes.py                # é¡åˆ¥æ˜ å°„
â”‚   â””â”€â”€ detection_converter.py         # Detection2DArray è½‰æ›
â”œâ”€â”€ launch/
â”‚   â””â”€â”€ coco_detector.launch.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ coco_params.yaml
â”œâ”€â”€ test/
â”‚   â””â”€â”€ test_coco_detector.py
â”œâ”€â”€ package.xml
â”œâ”€â”€ setup.py
â””â”€â”€ requirements-coco.txt
```

### æ ¸å¿ƒç¯€é»å¯¦ä½œ

#### `coco_detector_node.py`

```python
#!/usr/bin/env python3
"""
COCO Detector Node - Plan A ä¸»åŠ› VLM æ–¹æ¡ˆ
ä½¿ç”¨ TorchVision é è¨“ç·´æ¨¡å‹é€²è¡Œç‰©å“è­˜åˆ¥

Author: Go2 æ™ºæ…§å°‹ç‰©åœ˜éšŠ
Date: 2025/11/20
"""

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from vision_msgs.msg import Detection2DArray, Detection2D, ObjectHypothesisWithPose
from cv_bridge import CvBridge
import torch
import torchvision.transforms as T
from torchvision.models.detection import ssdlite320_mobilenet_v3_large
from torchvision.models.detection import SSDLite320_MobileNet_V3_Large_Weights
import numpy as np
from .coco_classes import COCO_CLASSES


class COCODetectorNode(Node):
    """COCO ç‰©å“åµæ¸¬ç¯€é»"""

    def __init__(self):
        super().__init__('coco_detector_node')

        # å®£å‘Šåƒæ•¸
        self.declare_parameter('device', 'cuda')  # 'cuda' or 'cpu'
        self.declare_parameter('confidence_threshold', 0.5)
        self.declare_parameter('nms_iou_threshold', 0.5)
        self.declare_parameter('max_detections', 10)
        self.declare_parameter('input_topic', '/camera/image_raw')
        self.declare_parameter('output_topic', '/detected_objects')

        # è®€å–åƒæ•¸
        self.device_name = self.get_parameter('device').value
        self.confidence_threshold = self.get_parameter('confidence_threshold').value
        self.nms_iou_threshold = self.get_parameter('nms_iou_threshold').value
        self.max_detections = self.get_parameter('max_detections').value

        # åˆå§‹åŒ– PyTorch æ¨¡å‹
        self.get_logger().info('æ­£åœ¨è¼‰å…¥ COCO æ¨¡å‹...')
        self.device = torch.device(self.device_name if torch.cuda.is_available() else 'cpu')

        weights = SSDLite320_MobileNet_V3_Large_Weights.COCO_V1
        self.model = ssdlite320_mobilenet_v3_large(weights=weights)
        self.model.eval()
        self.model = self.model.to(self.device)

        self.get_logger().info(f'æ¨¡å‹è¼‰å…¥æˆåŠŸï¼Œé‹è¡Œæ–¼: {self.device}')

        # å½±åƒè½‰æ›
        self.transform = T.Compose([
            T.ToTensor(),
        ])

        # CV Bridge
        self.bridge = CvBridge()

        # ROS2 è¨‚é–±èˆ‡ç™¼ä½ˆ
        self.subscription = self.create_subscription(
            Image,
            self.get_parameter('input_topic').value,
            self.image_callback,
            10
        )

        self.publisher = self.create_publisher(
            Detection2DArray,
            self.get_parameter('output_topic').value,
            10
        )

        self.get_logger().info('COCO Detector Node å·²å•Ÿå‹•')

    def image_callback(self, msg: Image):
        """è™•ç†æ¥æ”¶åˆ°çš„å½±åƒ"""
        try:
            # è½‰æ› ROS Image åˆ° OpenCV
            cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='rgb8')

            # é è™•ç†
            image_tensor = self.transform(cv_image).unsqueeze(0).to(self.device)

            # æ¨è«–
            with torch.no_grad():
                predictions = self.model(image_tensor)[0]

            # è½‰æ›ç‚º Detection2DArray
            detections = self.convert_to_detection2d_array(
                predictions,
                msg.header,
                cv_image.shape[:2]
            )

            # ç™¼ä½ˆçµæœ
            self.publisher.publish(detections)

            self.get_logger().info(
                f'åµæ¸¬åˆ° {len(detections.detections)} å€‹ç‰©å“',
                throttle_duration_sec=2.0  # æ¯ 2 ç§’æœ€å¤šé¡¯ç¤ºä¸€æ¬¡
            )

        except Exception as e:
            self.get_logger().error(f'è™•ç†å½±åƒæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}')

    def convert_to_detection2d_array(self, predictions, header, image_shape):
        """å°‡ PyTorch é æ¸¬çµæœè½‰æ›ç‚º ROS2 Detection2DArray"""
        detections_msg = Detection2DArray()
        detections_msg.header = header

        # éæ¿¾ä½ä¿¡å¿ƒåº¦çš„åµæ¸¬
        scores = predictions['scores'].cpu().numpy()
        labels = predictions['labels'].cpu().numpy()
        boxes = predictions['boxes'].cpu().numpy()

        mask = scores >= self.confidence_threshold
        scores = scores[mask][:self.max_detections]
        labels = labels[mask][:self.max_detections]
        boxes = boxes[mask][:self.max_detections]

        height, width = image_shape

        for score, label, box in zip(scores, labels, boxes):
            detection = Detection2D()

            # Bounding box (è½‰æ›ç‚ºæ­¸ä¸€åŒ–åº§æ¨™)
            detection.bbox.center.position.x = float((box[0] + box[2]) / 2 / width)
            detection.bbox.center.position.y = float((box[1] + box[3]) / 2 / height)
            detection.bbox.size_x = float((box[2] - box[0]) / width)
            detection.bbox.size_y = float((box[3] - box[1]) / height)

            # ç‰©å“é¡åˆ¥èˆ‡ä¿¡å¿ƒåº¦
            hypothesis = ObjectHypothesisWithPose()
            hypothesis.hypothesis.class_id = COCO_CLASSES.get(int(label), f"æœªçŸ¥é¡åˆ¥ {label}")
            hypothesis.hypothesis.score = float(score)

            detection.results.append(hypothesis)
            detections_msg.detections.append(detection)

        return detections_msg


def main(args=None):
    rclpy.init(args=args)
    node = COCODetectorNode()

    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()
```

#### `coco_classes.py`

```python
"""COCO è³‡æ–™é›†é¡åˆ¥æ˜ å°„ï¼ˆç¹é«”ä¸­æ–‡ï¼‰"""

COCO_CLASSES = {
    1: "äºº", 2: "è…³è¸è»Š", 3: "æ±½è»Š", 4: "æ©Ÿè»Š", 5: "é£›æ©Ÿ",
    6: "å…¬è»Š", 7: "ç«è»Š", 8: "å¡è»Š", 9: "èˆ¹", 10: "ç´…ç¶ ç‡ˆ",
    11: "æ¶ˆé˜²æ “", 13: "åœæ­¢æ¨™èªŒ", 14: "åœè»Šæ”¶è²»è¡¨", 15: "é•·æ¤…", 16: "é³¥",
    17: "è²“", 18: "ç‹—", 19: "é¦¬", 20: "ç¾Š", 21: "ç‰›",
    22: "å¤§è±¡", 23: "ç†Š", 24: "æ–‘é¦¬", 25: "é•·é ¸é¹¿", 27: "èƒŒåŒ…",
    28: "é›¨å‚˜", 31: "æ‰‹æåŒ…", 32: "é ˜å¸¶", 33: "è¡Œæç®±", 34: "é£›ç›¤",
    35: "æ»‘é›ªæ¿", 36: "æ»‘é›ªæ¿", 37: "é‹å‹•çƒ", 38: "é¢¨ç®", 39: "æ£’çƒæ£’",
    40: "æ£’çƒæ‰‹å¥—", 41: "æ»‘æ¿", 42: "è¡æµªæ¿", 43: "ç¶²çƒæ‹", 44: "ç“¶å­",
    45: "é…’æ¯", 46: "æ¯å­", 47: "å‰å­", 48: "åˆ€", 49: "æ¹¯åŒ™",
    50: "ç¢—", 51: "é¦™è•‰", 52: "è˜‹æœ", 53: "ä¸‰æ˜æ²»", 54: "æ©˜å­",
    55: "èŠ±æ¤°èœ", 56: "ç´…è˜¿è””", 57: "ç†±ç‹—", 58: "æŠ«è–©", 59: "ç”œç”œåœˆ",
    60: "è›‹ç³•", 61: "æ¤…å­", 62: "æ²™ç™¼", 63: "ç›†æ ½æ¤ç‰©", 64: "åºŠ",
    67: "é¤æ¡Œ", 70: "é¦¬æ¡¶", 72: "é›»è¦–", 73: "ç­†è¨˜å‹é›»è…¦", 74: "æ»‘é¼ ",
    75: "é™æ§å™¨", 76: "éµç›¤", 77: "æ‰‹æ©Ÿ", 78: "å¾®æ³¢çˆ", 79: "çƒ¤ç®±",
    80: "çƒ¤éºµåŒ…æ©Ÿ", 81: "æ°´æ§½", 82: "å†°ç®±", 84: "æ›¸", 85: "æ™‚é˜",
    86: "èŠ±ç“¶", 87: "å‰ªåˆ€", 88: "æ³°è¿ªç†Š", 89: "å¹é¢¨æ©Ÿ", 90: "ç‰™åˆ·"
}

# åå‘æ˜ å°„ï¼ˆç¹é«”ä¸­æ–‡ â†’ IDï¼‰
COCO_CLASSES_ZH_TO_ID = {v: k for k, v in COCO_CLASSES.items()}
```

### Launch æ–‡ä»¶

#### `coco_detector.launch.py`

```python
from launch import LaunchDescription
from launch_ros.actions import Node
from launch.actions import DeclareLaunchArgument
from launch.substitutions import LaunchConfiguration


def generate_launch_description():
    return LaunchDescription([
        # å®£å‘Šåƒæ•¸
        DeclareLaunchArgument(
            'device',
            default_value='cuda',
            description='æ¨è«–è£ç½® (cuda/cpu)'
        ),

        DeclareLaunchArgument(
            'confidence_threshold',
            default_value='0.5',
            description='ä¿¡å¿ƒåº¦é–€æª»'
        ),

        # COCO Detector Node
        Node(
            package='vision_vlm',
            executable='coco_detector_node',
            name='coco_detector',
            output='screen',
            parameters=[{
                'device': LaunchConfiguration('device'),
                'confidence_threshold': LaunchConfiguration('confidence_threshold'),
                'input_topic': '/camera/image_raw',
                'output_topic': '/detected_objects',
            }]
        ),
    ])
```

### åƒæ•¸é…ç½®æª”

#### `config/coco_params.yaml`

```yaml
coco_detector:
  ros__parameters:
    # æ¨è«–è£ç½®
    device: "cuda"  # å¯é¸ï¼šcuda, cpu

    # åµæ¸¬åƒæ•¸
    confidence_threshold: 0.5      # ä¿¡å¿ƒåº¦é–€æª»ï¼ˆ0.0-1.0ï¼‰
    nms_iou_threshold: 0.5         # NMS IoU é–€æª»
    max_detections: 10             # æœ€å¤šåµæ¸¬æ•¸é‡

    # ROS2 Topics
    input_topic: "/camera/image_raw"
    output_topic: "/detected_objects"

    # æ•ˆèƒ½å„ªåŒ–
    use_fp16: false                # æ˜¯å¦ä½¿ç”¨ FP16ï¼ˆéœ€ GPU æ”¯æ´ï¼‰
    batch_size: 1                  # æ‰¹æ¬¡å¤§å°
```

---

## æ¸¬è©¦èˆ‡é©—è­‰

### å–®å…ƒæ¸¬è©¦

```python
# test/test_coco_detector.py
import unittest
import torch
from vision_vlm.coco_detector_node import COCODetectorNode


class TestCOCODetector(unittest.TestCase):

    def test_model_loading(self):
        """æ¸¬è©¦æ¨¡å‹è¼‰å…¥"""
        import rclpy
        rclpy.init()

        node = COCODetectorNode()
        self.assertIsNotNone(node.model)
        self.assertEqual(node.device.type, 'cuda')

        node.destroy_node()
        rclpy.shutdown()

    def test_coco_classes(self):
        """æ¸¬è©¦ COCO é¡åˆ¥æ˜ å°„"""
        from vision_vlm.coco_classes import COCO_CLASSES, COCO_CLASSES_ZH_TO_ID

        self.assertEqual(COCO_CLASSES[75], "é™æ§å™¨")
        self.assertEqual(COCO_CLASSES_ZH_TO_ID["æ‰‹æ©Ÿ"], 77)
        self.assertEqual(len(COCO_CLASSES), 80)


if __name__ == '__main__':
    unittest.main()
```

### æ•´åˆæ¸¬è©¦

```bash
# 1. å•Ÿå‹• Go2 é©…å‹•ï¼ˆæ¨¡æ“¬æˆ–å¯¦æ©Ÿï¼‰
export ROBOT_IP="192.168.1.100"
ros2 launch go2_robot_sdk robot.launch.py

# 2. å•Ÿå‹• COCO Detector
ros2 launch vision_vlm coco_detector.launch.py

# 3. æª¢æŸ¥åµæ¸¬çµæœ
ros2 topic echo /detected_objects

# 4. æª¢æŸ¥æ¨è«–é »ç‡
ros2 topic hz /detected_objects
```

**é æœŸè¼¸å‡º**ï¼š
```
average rate: 15.234
  min: 0.065s max: 0.068s std dev: 0.00123s window: 100
```

### æ•ˆèƒ½æ¸¬è©¦

```bash
# GPU è¨˜æ†¶é«”ä½¿ç”¨ç›£æ§
watch -n 1 nvidia-smi

# é æœŸï¼šç´„ 1-2 GB VRAMï¼ˆMobileNet SSDï¼‰
```

---

## æ•ˆèƒ½å„ªåŒ–

### 1. FP16 åŠç²¾åº¦æ¨è«–

```python
# ä¿®æ”¹ coco_detector_node.py
if self.get_parameter('use_fp16').value and self.device.type == 'cuda':
    self.model = self.model.half()  # è½‰æ›ç‚º FP16
    self.get_logger().info('å·²å•Ÿç”¨ FP16 åŠç²¾åº¦æ¨è«–')
```

**æ•ˆæœ**ï¼š
- âœ… æ¨è«–é€Ÿåº¦æå‡ ~1.5x
- âœ… VRAM ä½¿ç”¨æ¸›åŠ
- âš ï¸ æº–ç¢ºç‡å¯èƒ½ç•¥é™ï¼ˆ< 1%ï¼‰

### 2. TorchScript ç·¨è­¯

```python
# åœ¨æ¨¡å‹è¼‰å…¥å¾Œ
example_input = torch.rand(1, 3, 640, 640).to(self.device)
self.model = torch.jit.trace(self.model, example_input)
self.get_logger().info('å·²ä½¿ç”¨ TorchScript ç·¨è­¯æ¨¡å‹')
```

**æ•ˆæœ**ï¼š
- âœ… æ¨è«–é€Ÿåº¦æå‡ ~1.2x
- âœ… æ›´å¥½çš„ GPU æ ¸å¿ƒåˆ©ç”¨ç‡

### 3. å½±åƒé™é »

```python
# ä¸æ˜¯æ¯å¹€éƒ½æ¨è«–ï¼Œè€Œæ˜¯é™é »åˆ° 5 Hz
self.last_inference_time = self.get_clock().now()
self.inference_interval = 0.2  # 200ms = 5 Hz

def image_callback(self, msg):
    now = self.get_clock().now()
    if (now - self.last_inference_time).nanoseconds < self.inference_interval * 1e9:
        return  # è·³éæ­¤å¹€

    self.last_inference_time = now
    # ... æ­£å¸¸è™•ç†
```

---

## æ•…éšœæ’é™¤

### å•é¡Œ 1ï¼šCUDA Out of Memory

**ç—‡ç‹€**ï¼š
```
RuntimeError: CUDA out of memory. Tried to allocate 1.50 GiB
```

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```python
# 1. ä½¿ç”¨è¼ƒå°çš„æ¨¡å‹
from torchvision.models.detection import ssd300_vgg16

# 2. å•Ÿç”¨ FP16
model = model.half()

# 3. æ¸…ç©º GPU å¿«å–
torch.cuda.empty_cache()
```

### å•é¡Œ 2ï¼šæ¨è«–é€Ÿåº¦æ…¢

**ç—‡ç‹€**ï¼š< 5 FPS

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```bash
# æª¢æŸ¥æ˜¯å¦ä½¿ç”¨ GPU
nvidia-smi

# ç¢ºèª model åœ¨ GPU ä¸Š
python3 -c "import torch; print(next(model.parameters()).device)"
```

### å•é¡Œ 3ï¼šç„¡æ³•åµæ¸¬ç‰¹å®šç‰©å“

**ç—‡ç‹€**ï¼šçœ¼é¡ã€é‘°åŒ™åµæ¸¬ä¸åˆ°

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
- é€™äº›ç‰©å“ä¸åœ¨ COCO 80 é¡ä¸­
- éœ€è¦ä½¿ç”¨ Gemini API ä½œç‚ºè£œå……ï¼ˆè¦‹ `gemini_vlm_backup.md`ï¼‰
- æˆ–åœ¨ç¬¬äºŒéšæ®µé€²è¡Œæ¨¡å‹å¾®èª¿

---

## ä¸‹ä¸€æ­¥

1. âœ… **å®Œæˆ COCO Detector ç¯€é»é–‹ç™¼**ï¼ˆæœ¬æ–‡æª”ï¼‰
2. ğŸŸ¡ **æ•´åˆåº§æ¨™è½‰æ›ç³»çµ±**ï¼ˆè¦‹ `coordinate_transformation.md`ï¼‰
3. ğŸŸ¡ **ç«¯åˆ°ç«¯æ¸¬è©¦**ï¼ˆè¦‹ `testing_plan.md`ï¼‰
4. ğŸŸ¡ **12/17 ç™¼è¡¨æº–å‚™**ï¼ˆè¦‹ `presentation_1217_plan.md`ï¼‰

---

## åƒè€ƒè³‡æ–™

- [TorchVision Detection Models](https://pytorch.org/vision/stable/models.html#object-detection)
- [COCO Dataset](https://cocodataset.org/)
- [ROS2 Vision Messages](https://github.com/ros-perception/vision_msgs)
- [Go2 SDK Documentation](../CLAUDE.md)

---

**æ–‡ä»¶ç¶­è­·**ï¼šæœ¬æ–‡ä»¶ç”± Go2 æ™ºæ…§å°‹ç‰©åœ˜éšŠç¶­è­·ï¼Œå¦‚æœ‰å•é¡Œè«‹åƒè€ƒ `docs/README.md`ã€‚
