# åº§æ¨™è½‰æ›ç³»çµ±è¨­è¨ˆæ–‡ä»¶

**å¥—ä»¶åç¨±ï¼š** `coordinate_transformer`
**ä¸»è¦ç¯€é»ï¼š** `lidar_projection_node` / `ground_assumption_node`
**é–‹ç™¼é€±æ¬¡ï¼š** W7-W8
**é›£åº¦ï¼š** â­â­â­â­ é«˜

**é‡è¦æé†’ï¼š**
- æœ¬æ–‡ä»¶ä¸­ä½¿ç”¨ `camera_link` ä»£è¡¨ç›¸æ©Ÿåº§æ¨™ç³» frameï¼Œå¯¦éš›å¯¦ä½œæ™‚è«‹å°æ‡‰çœŸå¯¦ URDF ä¸­çš„ frame åç¨±ï¼ˆå¯èƒ½æ˜¯ `front_camera_link` æˆ–å…¶ä»–ï¼‰
- ä½¿ç”¨å‰è«‹å…ˆåŸ·è¡Œ `ros2 run tf2_tools view_frames` ç¢ºèªå¯¦éš› frame åç¨±

---

## ğŸ“‹ ç›®æ¨™

å¯¦ç¾å¾ **2D åœ–åƒåº§æ¨™** åˆ° **3D ä¸–ç•Œåº§æ¨™** çš„å®Œæ•´è½‰æ›éˆè·¯ï¼š

```
VLM è¼¸å‡º [u, v] åƒç´ åº§æ¨™
         â†“
ç›¸æ©Ÿå…§åƒ + æ·±åº¦è³‡è¨Š
         â†“
3D æœ¬é«”åº§æ¨™ [x, y, z] (base_link frame)
         â†“
TF2 è½‰æ›
         â†“
3D ä¸–ç•Œåº§æ¨™ [X, Y, Z] (map frame)
         â†“
Nav2 å°èˆªç›®æ¨™
```

---

## ğŸ¯ æ ¸å¿ƒæŒ‘æˆ°

### å•é¡Œï¼šGo2 ç„¡æ·±åº¦ç›¸æ©Ÿï¼
**ç¾æœ‰æ„Ÿæ¸¬å™¨**ï¼š
- âœ… RGB ç›¸æ©Ÿï¼ˆ720p/1080pï¼‰
- âœ… LiDARï¼ˆUnitree L1ï¼Œé»é›²æ•¸æ“šï¼‰
- âŒ **ç„¡æ·±åº¦ç›¸æ©Ÿ**ï¼ˆRealSense/Kinect ç­‰ï¼‰

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
1. **Plan Aï¼ˆæ¨è–¦ï¼‰**ï¼šLiDAR é»é›²æŠ•å½±æ³•
2. **Plan Bï¼ˆå‚™ç”¨ï¼‰**ï¼šåœ°é¢å‡è¨­æ³•
3. **Plan Cï¼ˆDemo å‚™æ¡ˆï¼‰**ï¼šé æ¨™è¨»åº§æ¨™

---

## ğŸ—ï¸ ç³»çµ±æ¶æ§‹

### æ–¹æ³• Aï¼šLiDAR é»é›²æŠ•å½±æ³•

#### åŸç†
å°‡ LiDAR é»é›²æŠ•å½±åˆ°ç›¸æ©Ÿåœ–åƒå¹³é¢ï¼Œå»ºç«‹åƒç´  â†’ 3D é»çš„å°æ‡‰é—œä¿‚ã€‚

#### æ•¸å­¸åŸºç¤

**æ­¥é©Ÿ 1ï¼šåº§æ¨™ç³»è½‰æ›ï¼ˆLiDAR â†’ Cameraï¼‰**
```python
# ä½¿ç”¨ TF2 å–å¾—è½‰æ›çŸ©é™£
T_camera_base = tf_buffer.lookup_transform('camera_link', 'base_link', time)

# å°‡é»é›²å¾ base_link è½‰åˆ° camera_link
for point in pointcloud:
    p_camera = T_camera_base * p_base
```

**æ­¥é©Ÿ 2ï¼š3D â†’ 2D æŠ•å½±ï¼ˆç›¸æ©Ÿå…§åƒï¼‰**

ç›¸æ©Ÿå…§åƒçŸ©é™£ Kï¼ˆå·²æ–¼ calibration YAML ä¸­æä¾›ï¼‰ï¼š
$$
K = \begin{bmatrix}
f_x & 0 & c_x \\
0 & f_y & c_y \\
0 & 0 & 1
\end{bmatrix}
$$

æŠ•å½±å…¬å¼ï¼š
$$
\begin{bmatrix} u \\ v \\ 1 \end{bmatrix} = \frac{1}{Z} K \begin{bmatrix} X \\ Y \\ Z \end{bmatrix}
$$

å…¶ä¸­ï¼š
- $(X, Y, Z)$ï¼šç›¸æ©Ÿåº§æ¨™ç³»ä¸‹çš„ 3D é»
- $(u, v)$ï¼šåœ–åƒåƒç´ åº§æ¨™
- $f_x, f_y$ï¼šç„¦è·
- $c_x, c_y$ï¼šå…‰å­¸ä¸­å¿ƒ

**æ­¥é©Ÿ 3ï¼šå»ºç«‹æŸ¥æ‰¾è¡¨**
```python
# ç‚ºæ¯å€‹åƒç´ å»ºç«‹å°æ‡‰çš„ 3D é»
depth_map = {}
for point_3d in camera_points:
    u, v = project_to_image(point_3d, K)
    if 0 <= u < width and 0 <= v < height:
        depth_map[(u, v)] = point_3d
```

**æ­¥é©Ÿ 4ï¼šæŸ¥è©¢ VLM åº§æ¨™**
```python
# VLM è¼¸å‡ºçš„ Bbox ä¸­å¿ƒ
u_vlm, v_vlm = detection.bbox.center.x, detection.bbox.center.y

# æŸ¥æ‰¾å°æ‡‰çš„ 3D é»ï¼ˆå–é„°è¿‘å€åŸŸå¹³å‡ï¼‰
neighbors = [(u_vlm + du, v_vlm + dv) for du in [-5, 0, 5] for dv in [-5, 0, 5]]
points_3d = [depth_map.get((u, v)) for u, v in neighbors if (u, v) in depth_map]
point_3d_avg = np.mean(points_3d, axis=0)  # å¹³å‡é™å™ª
```

#### è³‡æ–™æµå‘åœ–

```mermaid
graph TD
    A[point_cloud2<br/>LiDAR é»é›²] --> B[TF2 è½‰æ›<br/>base_link â†’ camera_link]
    C[camera_info<br/>å…§åƒçŸ©é™£ K] --> D[3D â†’ 2D æŠ•å½±]
    B --> D
    D --> E[å»ºç«‹æ·±åº¦åœ–<br/>dict: pixel â†’ 3D point]
    F[/detected_objects<br/>VLM è¼¸å‡º] --> G[æå– Bbox ä¸­å¿ƒ<br/>u, v]
    G --> H[æŸ¥æ‰¾æ·±åº¦åœ–]
    E --> H
    H --> I[3D æœ¬é«”åº§æ¨™<br/>PoseStamped base_link]
    I --> J[TF2 è½‰æ›<br/>base_link â†’ map]
    J --> K[/object_pose_world<br/>PoseStamped map]
```

---

### æ–¹æ³• Bï¼šåœ°é¢å‡è¨­æ³•

#### åŸç†
å‡è¨­ç›®æ¨™ç‰©é«”ä½æ–¼åœ°é¢å¹³é¢ï¼ˆ$Z_{map} = 0$ï¼‰ï¼Œä½¿ç”¨å°„ç·š-å¹³é¢äº¤é»è¨ˆç®— 3D åº§æ¨™ã€‚

#### æ•¸å­¸æ¨å°

**å‡è¨­**ï¼š
- åœ°é¢å¹³é¢ï¼š$Z_{map} = 0$ï¼ˆåœ¨ map frame ä¸­ï¼‰
- å·²çŸ¥ï¼šç›¸æ©Ÿä½å§¿ã€å…§åƒã€VLM åƒç´ åº§æ¨™

**æ­¥é©Ÿ 1ï¼šè¨ˆç®—ç›¸æ©Ÿå°„ç·š**

å¾åƒç´  $(u, v)$ åæŠ•å½±ç‚ºç›¸æ©Ÿå°„ç·šï¼š
$$
\vec{r}_{camera} = K^{-1} \begin{bmatrix} u \\ v \\ 1 \end{bmatrix}
$$

æ­£è¦åŒ–å¾Œï¼š
$$
\vec{d}_{camera} = \frac{\vec{r}_{camera}}{||\vec{r}_{camera}||}
$$

**æ­¥é©Ÿ 2ï¼šè½‰æ›åˆ°ä¸–ç•Œåº§æ¨™ç³»**

ä½¿ç”¨ TF2 å–å¾—ç›¸æ©Ÿä½å§¿ $T_{map \leftarrow camera}$ï¼š
```python
T = tf_buffer.lookup_transform('map', 'camera_link', time)
camera_position = [T.translation.x, T.translation.y, T.translation.z]
camera_rotation = [T.rotation.x, T.rotation.y, T.rotation.z, T.rotation.w]

# æ—‹è½‰å°„ç·šæ–¹å‘
d_world = quaternion_rotation(d_camera, camera_rotation)
```

**æ­¥é©Ÿ 3ï¼šå°„ç·š-å¹³é¢äº¤é»**

å°„ç·šæ–¹ç¨‹ï¼š$\vec{P}(t) = \vec{C} + t \vec{d}$ï¼ˆ$\vec{C}$ ç‚ºç›¸æ©Ÿä½ç½®ï¼‰

å¹³é¢æ–¹ç¨‹ï¼š$Z = 0$

æ±‚è§£ $t$ï¼š
$$
t = \frac{-C_z}{d_z}
$$

äº¤é»åº§æ¨™ï¼š
$$
\begin{bmatrix} X_{world} \\ Y_{world} \\ 0 \end{bmatrix} = \vec{C} + t \vec{d}
$$

#### é™åˆ¶èˆ‡é©ç”¨å ´æ™¯
- âœ… é©ç”¨ï¼šåœ°é¢ç‰©é«”ï¼ˆçœ¼é¡ã€é‘°åŒ™ç­‰ï¼‰
- âŒ ä¸é©ç”¨ï¼šæ‡¸æ›ç‰©é«”ï¼ˆæ¶ä¸Šçš„æ¯å­ï¼‰
- âš ï¸ èª¤å·®ï¼šåœ°é¢ä¸å¹³æ•´æ™‚èª¤å·®å¢å¤§

---

## ğŸ› ï¸ å¯¦ä½œç´°ç¯€

### å¥—ä»¶çµæ§‹

```
src/coordinate_transformer/
â”œâ”€â”€ coordinate_transformer/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ lidar_projection_node.py      # Plan A å¯¦ä½œ
â”‚   â”œâ”€â”€ ground_assumption_node.py     # Plan B å¯¦ä½œ
â”‚   â”œâ”€â”€ projection_utils.py           # æŠ•å½±å·¥å…·å‡½æ•¸
â”‚   â”œâ”€â”€ tf_utils.py                   # TF2 è¼”åŠ©å·¥å…·
â”‚   â””â”€â”€ calibration_loader.py         # è¼‰å…¥ç›¸æ©Ÿå…§åƒ
â”œâ”€â”€ config/
â”‚   â””â”€â”€ transformer_params.yaml
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ test_projection.py
â”‚   â””â”€â”€ test_ground_assumption.py
â”œâ”€â”€ launch/
â”‚   â””â”€â”€ transformer.launch.py
â”œâ”€â”€ package.xml
â””â”€â”€ setup.py
```

---

### æ ¸å¿ƒç¨‹å¼ç¢¼

#### A. `projection_utils.py`ï¼ˆæŠ•å½±å·¥å…·ï¼‰

```python
"""
ç›¸æ©ŸæŠ•å½±å·¥å…·å‡½æ•¸
"""
import numpy as np
from typing import Tuple, List, Optional


class ProjectionUtils:
    @staticmethod
    def load_camera_intrinsics(camera_info_msg) -> np.ndarray:
        """
        å¾ CameraInfo è¨Šæ¯æå–å…§åƒçŸ©é™£

        Returns:
            3x3 numpy array
        """
        K = np.array(camera_info_msg.k).reshape(3, 3)
        return K

    @staticmethod
    def project_3d_to_2d(
        points_3d: np.ndarray,
        K: np.ndarray
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        """
        å°‡ 3D é»æŠ•å½±åˆ° 2D åœ–åƒå¹³é¢

        Args:
            points_3d: Nx3 array (X, Y, Z in camera frame)
            K: 3x3 å…§åƒçŸ©é™£

        Returns:
            u: N array (x åƒç´ åº§æ¨™)
            v: N array (y åƒç´ åº§æ¨™)
            valid_mask: N boolean array (æœ‰æ•ˆé»çš„é®ç½©ï¼ŒZ > 0)
        """
        # åªä¿ç•™ç›¸æ©Ÿå‰æ–¹çš„é»ï¼ˆZ > 0ï¼‰
        valid_mask = points_3d[:, 2] > 0
        points_3d_valid = points_3d[valid_mask]

        # æŠ•å½±ï¼ˆé½Šæ¬¡åº§æ¨™ï¼‰
        uv_homogeneous = K @ points_3d_valid.T  # 3xN
        u = uv_homogeneous[0, :] / uv_homogeneous[2, :]
        v = uv_homogeneous[1, :] / uv_homogeneous[2, :]

        return u.astype(int), v.astype(int), valid_mask

    @staticmethod
    def unproject_2d_to_ray(
        u: float,
        v: float,
        K: np.ndarray
    ) -> np.ndarray:
        """
        å¾ 2D åƒç´ åæŠ•å½±ç‚º 3D å°„ç·šï¼ˆå–®ä½å‘é‡ï¼‰

        Args:
            u, v: åƒç´ åº§æ¨™
            K: 3x3 å…§åƒçŸ©é™£

        Returns:
            3D å–®ä½å‘é‡ (camera frame)
        """
        K_inv = np.linalg.inv(K)
        pixel_homogeneous = np.array([u, v, 1.0])
        ray = K_inv @ pixel_homogeneous
        ray_normalized = ray / np.linalg.norm(ray)
        return ray_normalized

    @staticmethod
    def ray_plane_intersection(
        ray_origin: np.ndarray,
        ray_direction: np.ndarray,
        plane_z: float = 0.0
    ) -> Optional[np.ndarray]:
        """
        è¨ˆç®—å°„ç·šèˆ‡å¹³é¢ (Z = plane_z) çš„äº¤é»

        Args:
            ray_origin: å°„ç·šèµ·é» (3D)
            ray_direction: å°„ç·šæ–¹å‘ï¼ˆå–®ä½å‘é‡ï¼‰
            plane_z: å¹³é¢ Z åº§æ¨™

        Returns:
            äº¤é» (X, Y, Z) æˆ– Noneï¼ˆç„¡äº¤é»ï¼‰
        """
        # é¿å…é™¤ä»¥é›¶
        if abs(ray_direction[2]) < 1e-6:
            return None

        # è¨ˆç®—åƒæ•¸ t
        t = (plane_z - ray_origin[2]) / ray_direction[2]

        # å°„ç·šå‘å¾Œï¼ˆt < 0ï¼‰
        if t < 0:
            return None

        # è¨ˆç®—äº¤é»
        intersection = ray_origin + t * ray_direction
        return intersection
```

---

#### B. `lidar_projection_node.py`ï¼ˆPlan A ä¸»ç¯€é»ï¼‰

```python
"""
LiDAR é»é›²æŠ•å½±ç¯€é»
å»ºç«‹åƒç´  â†’ 3D é»çš„å°æ‡‰é—œä¿‚
"""
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import PointCloud2, CameraInfo, Image
from vision_msgs.msg import Detection2DArray
from geometry_msgs.msg import PoseStamped, TransformStamped
from tf2_ros import Buffer, TransformListener
import numpy as np
from cv_bridge import CvBridge
import message_filters

from .projection_utils import ProjectionUtils


class LiDARProjectionNode(Node):
    def __init__(self):
        super().__init__('lidar_projection_node')

        # åƒæ•¸
        self.declare_parameter('point_cloud_topic', 'point_cloud2')
        self.declare_parameter('camera_info_topic', 'camera/camera_info')
        self.declare_parameter('detection_topic', '/detected_objects')
        self.declare_parameter('image_width', 1280)
        self.declare_parameter('image_height', 720)
        self.declare_parameter('neighbor_radius', 5)  # æŸ¥æ‰¾é„°è¿‘åƒç´ ç¯„åœ

        self.pc_topic = self.get_parameter('point_cloud_topic').value
        self.cam_info_topic = self.get_parameter('camera_info_topic').value
        self.det_topic = self.get_parameter('detection_topic').value
        self.img_width = self.get_parameter('image_width').value
        self.img_height = self.get_parameter('image_height').value
        self.neighbor_radius = self.get_parameter('neighbor_radius').value

        # TF2
        self.tf_buffer = Buffer()
        self.tf_listener = TransformListener(self.tf_buffer, self)

        # å·¥å…·
        self.projection_utils = ProjectionUtils()
        self.bridge = CvBridge()

        # ç‹€æ…‹
        self.camera_intrinsics = None
        self.depth_map = {}  # {(u, v): [x, y, z]}

        # è¨‚é–±å™¨ï¼ˆåŒæ­¥ PointCloud + CameraInfoï¼‰
        self.pc_sub = message_filters.Subscriber(self, PointCloud2, self.pc_topic)
        self.cam_info_sub = message_filters.Subscriber(self, CameraInfo, self.cam_info_topic)

        ts = message_filters.ApproximateTimeSynchronizer(
            [self.pc_sub, self.cam_info_sub],
            queue_size=10,
            slop=0.1  # 100ms å®¹å·®
        )
        ts.registerCallback(self.pointcloud_callback)

        # è¨‚é–± VLM åµæ¸¬çµæœ
        self.det_sub = self.create_subscription(
            Detection2DArray,
            self.det_topic,
            self.detection_callback,
            10
        )

        # ç™¼ä½ˆå™¨
        self.pose_pub = self.create_publisher(
            PoseStamped,
            '/object_pose_world',
            10
        )

        self.get_logger().info('LiDAR æŠ•å½±ç¯€é»å·²å•Ÿå‹•')

    def pointcloud_callback(self, pc_msg: PointCloud2, cam_info_msg: CameraInfo):
        """è™•ç†é»é›²èˆ‡ç›¸æ©Ÿå…§åƒ"""
        try:
            # è¼‰å…¥å…§åƒï¼ˆé¦–æ¬¡ï¼‰
            if self.camera_intrinsics is None:
                self.camera_intrinsics = self.projection_utils.load_camera_intrinsics(cam_info_msg)
                self.get_logger().info(f'ç›¸æ©Ÿå…§åƒå·²è¼‰å…¥:\n{self.camera_intrinsics}')

            # è½‰æ›é»é›²åˆ° numpy array
            points_base = self.pointcloud2_to_array(pc_msg)  # Nx3

            # è½‰æ›åˆ°ç›¸æ©Ÿåº§æ¨™ç³»
            try:
                transform = self.tf_buffer.lookup_transform(
                    'camera_link',
                    'base_link',
                    pc_msg.header.stamp,
                    timeout=rclpy.duration.Duration(seconds=0.1)
                )
            except Exception as e:
                self.get_logger().warn(f'TF æŸ¥æ‰¾å¤±æ•—: {e}')
                return

            points_camera = self.transform_points(points_base, transform)

            # æŠ•å½±åˆ°åœ–åƒå¹³é¢
            u, v, valid_mask = self.projection_utils.project_3d_to_2d(
                points_camera,
                self.camera_intrinsics
            )

            # éæ¿¾åœ–åƒç¯„åœå¤–çš„é»
            valid_in_image = (u >= 0) & (u < self.img_width) & (v >= 0) & (v < self.img_height)
            u_valid = u[valid_in_image]
            v_valid = v[valid_in_image]
            points_camera_valid = points_camera[valid_mask][valid_in_image]

            # å»ºç«‹æ·±åº¦åœ–
            self.depth_map.clear()
            for i in range(len(u_valid)):
                pixel = (u_valid[i], v_valid[i])
                self.depth_map[pixel] = points_camera_valid[i]

            self.get_logger().debug(f'æ·±åº¦åœ–å·²æ›´æ–°ï¼š{len(self.depth_map)} å€‹åƒç´ ')

        except Exception as e:
            self.get_logger().error(f'é»é›²è™•ç†éŒ¯èª¤: {e}')

    def detection_callback(self, det_msg: Detection2DArray):
        """è™•ç† VLM åµæ¸¬çµæœ"""
        if not self.depth_map:
            self.get_logger().warn('æ·±åº¦åœ–å°šæœªå»ºç«‹ï¼Œç­‰å¾…é»é›²æ•¸æ“š')
            return

        for detection in det_msg.detections:
            try:
                # æå– Bbox ä¸­å¿ƒ
                u = int(detection.bbox.center.position.x)
                v = int(detection.bbox.center.position.y)

                # æŸ¥æ‰¾é„°è¿‘åƒç´ çš„ 3D é»
                neighbors = self.get_neighbor_points(u, v)
                if not neighbors:
                    self.get_logger().warn(f'åƒç´  ({u}, {v}) é™„è¿‘ç„¡æœ‰æ•ˆæ·±åº¦è³‡è¨Š')
                    continue

                # å¹³å‡é™å™ª
                point_3d_camera = np.mean(neighbors, axis=0)

                # è½‰æ›åˆ° base_link
                point_3d_base = self.transform_point_inverse(
                    point_3d_camera,
                    det_msg.header.stamp
                )

                # è½‰æ›åˆ° map
                point_3d_world = self.transform_to_map(
                    point_3d_base,
                    det_msg.header.stamp
                )

                # ç™¼ä½ˆçµæœ
                pose_msg = PoseStamped()
                pose_msg.header.stamp = self.get_clock().now().to_msg()
                pose_msg.header.frame_id = 'map'
                pose_msg.pose.position.x = point_3d_world[0]
                pose_msg.pose.position.y = point_3d_world[1]
                pose_msg.pose.position.z = point_3d_world[2]
                pose_msg.pose.orientation.w = 1.0  # ç„¡æ—‹è½‰

                self.pose_pub.publish(pose_msg)

                # æ—¥èªŒ
                obj_name = detection.results[0].hypothesis.class_id if detection.results else "æœªçŸ¥"
                self.get_logger().info(
                    f'ç‰©é«” "{obj_name}" ä¸–ç•Œåº§æ¨™: '
                    f'({point_3d_world[0]:.2f}, {point_3d_world[1]:.2f}, {point_3d_world[2]:.2f})'
                )

            except Exception as e:
                self.get_logger().error(f'åº§æ¨™è½‰æ›éŒ¯èª¤: {e}')

    def get_neighbor_points(self, u: int, v: int) -> List[np.ndarray]:
        """å–å¾—é„°è¿‘åƒç´ çš„ 3D é»"""
        neighbors = []
        for du in range(-self.neighbor_radius, self.neighbor_radius + 1):
            for dv in range(-self.neighbor_radius, self.neighbor_radius + 1):
                pixel = (u + du, v + dv)
                if pixel in self.depth_map:
                    neighbors.append(self.depth_map[pixel])
        return neighbors

    def transform_points(self, points: np.ndarray, transform: TransformStamped) -> np.ndarray:
        """è½‰æ›é»é›²ï¼ˆä½¿ç”¨ TFï¼‰"""
        # æå–æ—‹è½‰èˆ‡å¹³ç§»
        t = transform.transform.translation
        r = transform.transform.rotation

        # ä½¿ç”¨ scipy æˆ–æ‰‹å‹•å¯¦ä½œå››å…ƒæ•¸æ—‹è½‰
        from scipy.spatial.transform import Rotation
        rotation = Rotation.from_quat([r.x, r.y, r.z, r.w])

        points_rotated = rotation.apply(points)
        points_transformed = points_rotated + np.array([t.x, t.y, t.z])
        return points_transformed

    def transform_to_map(self, point_base: np.ndarray, timestamp) -> np.ndarray:
        """å°‡ base_link åº§æ¨™è½‰æ›åˆ° map"""
        try:
            transform = self.tf_buffer.lookup_transform(
                'map',
                'base_link',
                timestamp,
                timeout=rclpy.duration.Duration(seconds=0.1)
            )
            point_transformed = self.transform_points(point_base.reshape(1, 3), transform)
            return point_transformed[0]
        except Exception as e:
            self.get_logger().error(f'TF è½‰æ›å¤±æ•—: {e}')
            return point_base

    def pointcloud2_to_array(self, pc_msg: PointCloud2) -> np.ndarray:
        """è½‰æ› PointCloud2 ç‚º numpy array"""
        import sensor_msgs_py.point_cloud2 as pc2
        points = []
        for point in pc2.read_points(pc_msg, field_names=("x", "y", "z"), skip_nans=True):
            points.append([point[0], point[1], point[2]])
        return np.array(points)


def main(args=None):
    rclpy.init(args=args)
    node = LiDARProjectionNode()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()
```

---

#### C. `ground_assumption_node.py`ï¼ˆPlan B å‚™ç”¨ï¼‰

```python
"""
åœ°é¢å‡è¨­ç¯€é»ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰
å‡è¨­ç‰©é«”ä½æ–¼åœ°é¢å¹³é¢ (Z=0 in map frame)
"""
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import CameraInfo
from vision_msgs.msg import Detection2DArray
from geometry_msgs.msg import PoseStamped
from tf2_ros import Buffer, TransformListener
import numpy as np

from .projection_utils import ProjectionUtils


class GroundAssumptionNode(Node):
    def __init__(self):
        super().__init__('ground_assumption_node')

        # åƒæ•¸
        self.declare_parameter('camera_info_topic', 'camera/camera_info')
        self.declare_parameter('detection_topic', '/detected_objects')
        self.declare_parameter('ground_z', 0.0)  # åœ°é¢é«˜åº¦ï¼ˆmap frameï¼‰

        self.cam_info_topic = self.get_parameter('camera_info_topic').value
        self.det_topic = self.get_parameter('detection_topic').value
        self.ground_z = self.get_parameter('ground_z').value

        # TF2
        self.tf_buffer = Buffer()
        self.tf_listener = TransformListener(self.tf_buffer, self)

        # å·¥å…·
        self.projection_utils = ProjectionUtils()
        self.camera_intrinsics = None

        # è¨‚é–±å™¨
        self.cam_info_sub = self.create_subscription(
            CameraInfo,
            self.cam_info_topic,
            self.camera_info_callback,
            10
        )

        self.det_sub = self.create_subscription(
            Detection2DArray,
            self.det_topic,
            self.detection_callback,
            10
        )

        # ç™¼ä½ˆå™¨
        self.pose_pub = self.create_publisher(
            PoseStamped,
            '/object_pose_world',
            10
        )

        self.get_logger().info('åœ°é¢å‡è¨­ç¯€é»å·²å•Ÿå‹•')

    def camera_info_callback(self, msg: CameraInfo):
        if self.camera_intrinsics is None:
            self.camera_intrinsics = self.projection_utils.load_camera_intrinsics(msg)
            self.get_logger().info('ç›¸æ©Ÿå…§åƒå·²è¼‰å…¥')

    def detection_callback(self, det_msg: Detection2DArray):
        if self.camera_intrinsics is None:
            self.get_logger().warn('ç­‰å¾…ç›¸æ©Ÿå…§åƒ')
            return

        for detection in det_msg.detections:
            try:
                # æå–åƒç´ åº§æ¨™
                u = detection.bbox.center.position.x
                v = detection.bbox.center.position.y

                # åæŠ•å½±ç‚ºå°„ç·šï¼ˆç›¸æ©Ÿåº§æ¨™ç³»ï¼‰
                ray_camera = self.projection_utils.unproject_2d_to_ray(
                    u, v, self.camera_intrinsics
                )

                # å–å¾—ç›¸æ©Ÿä½å§¿ï¼ˆmap frameï¼‰
                transform = self.tf_buffer.lookup_transform(
                    'map',
                    'camera_link',
                    det_msg.header.stamp,
                    timeout=rclpy.duration.Duration(seconds=0.1)
                )

                camera_position = np.array([
                    transform.transform.translation.x,
                    transform.transform.translation.y,
                    transform.transform.translation.z
                ])

                # æ—‹è½‰å°„ç·šåˆ° map frame
                from scipy.spatial.transform import Rotation
                r = transform.transform.rotation
                rotation = Rotation.from_quat([r.x, r.y, r.z, r.w])
                ray_world = rotation.apply(ray_camera)

                # è¨ˆç®—å°„ç·š-å¹³é¢äº¤é»
                intersection = self.projection_utils.ray_plane_intersection(
                    camera_position,
                    ray_world,
                    self.ground_z
                )

                if intersection is None:
                    self.get_logger().warn('å°„ç·šæœªèˆ‡åœ°é¢ç›¸äº¤')
                    continue

                # ç™¼ä½ˆçµæœ
                pose_msg = PoseStamped()
                pose_msg.header.stamp = self.get_clock().now().to_msg()
                pose_msg.header.frame_id = 'map'
                pose_msg.pose.position.x = intersection[0]
                pose_msg.pose.position.y = intersection[1]
                pose_msg.pose.position.z = intersection[2]
                pose_msg.pose.orientation.w = 1.0

                self.pose_pub.publish(pose_msg)

                obj_name = detection.results[0].hypothesis.class_id if detection.results else "æœªçŸ¥"
                self.get_logger().info(
                    f'ç‰©é«” "{obj_name}" åœ°é¢æŠ•å½±åº§æ¨™: '
                    f'({intersection[0]:.2f}, {intersection[1]:.2f})'
                )

            except Exception as e:
                self.get_logger().error(f'åœ°é¢æŠ•å½±éŒ¯èª¤: {e}')


def main(args=None):
    rclpy.init(args=args)
    node = GroundAssumptionNode()
    rclpy.spin(node)
    node.destroy_node()
    rclpy.shutdown()
```

---

## ğŸ§ª æ¸¬è©¦èˆ‡æ ¡æ­£

### 1. æ ¡æ­£æµç¨‹

#### æº–å‚™å·¥ä½œ
1. åœ¨åœ°é¢æ”¾ç½®å·²çŸ¥ä½ç½®çš„æ¨™è¨˜ç‰©ï¼ˆå¦‚ ArUco Markerï¼‰
2. è¨˜éŒ„çœŸå¯¦åº§æ¨™ï¼ˆä½¿ç”¨æ²å°ºæ¸¬é‡ï¼‰

#### æ¸¬è©¦æ­¥é©Ÿ
```bash
# Terminal 1: å•Ÿå‹•ç³»çµ±
ros2 launch go2_robot_sdk robot.launch.py vlm:=true

# Terminal 2: å•Ÿå‹•åº§æ¨™è½‰æ›ç¯€é»
ros2 run coordinate_transformer lidar_projection_node

# Terminal 3: è¨˜éŒ„è½‰æ›çµæœ
ros2 topic echo /object_pose_world

# Terminal 4: åœ¨ RViz ä¸­å¯è¦–åŒ–
rviz2 -d config/coordinate_debug.rviz
```

#### èª¤å·®è¨ˆç®—
```python
# çœŸå¯¦åº§æ¨™ï¼ˆæ‰‹å‹•æ¸¬é‡ï¼‰
ground_truth = np.array([2.5, 1.0, 0.0])

# ç³»çµ±è¼¸å‡º
estimated = np.array([2.48, 1.05, 0.02])

# æ°´å¹³èª¤å·®
error_xy = np.linalg.norm(ground_truth[:2] - estimated[:2])
print(f"æ°´å¹³èª¤å·®: {error_xy * 100:.1f} cm")
```

### 2. æ•ˆèƒ½åŸºæº–

| æŒ‡æ¨™ | Plan A ç›®æ¨™ | Plan B ç›®æ¨™ |
|------|------------|------------|
| **æ°´å¹³èª¤å·®** | < 15 cm | < 25 cm |
| **è™•ç†å»¶é²** | < 0.2 s | < 0.1 s |
| **æˆåŠŸç‡** | > 90% | > 80% |

---

## ğŸ“Š éŒ¯èª¤è™•ç†

### å¸¸è¦‹å•é¡Œèˆ‡è§£æ±º

**Q1: æ·±åº¦åœ–ç¨€ç–ï¼ˆLiDAR é»ä¸å¤ ï¼‰**
```python
# è§£æ±ºï¼šå¢å¤§é„°è¿‘æœç´¢ç¯„åœ
self.neighbor_radius = 10  # å¾ 5 å¢è‡³ 10
```

**Q2: TF æŸ¥æ‰¾è¶…æ™‚**
```python
# è§£æ±ºï¼šå¢åŠ å®¹å·®æ™‚é–“
timeout=rclpy.duration.Duration(seconds=0.5)
```

**Q3: åœ°é¢å‡è¨­èª¤å·®å¤§**
```python
# è§£æ±ºï¼šæ ¡æ­£åœ°é¢é«˜åº¦
self.ground_z = -0.05  # æ ¹æ“šå¯¦éš›æ¸¬é‡èª¿æ•´
```

---

## ğŸ“š ç›¸é—œè³‡æº

- [TF2 æ•™å­¸](https://docs.ros.org/en/humble/Tutorials/Intermediate/Tf2/Tf2-Main.html)
- [ç›¸æ©Ÿæ¨™å®šåŸç†](https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html)
- [sensor_msgs/PointCloud2](http://docs.ros.org/en/api/sensor_msgs/html/msg/PointCloud2.html)

---

**æ–‡ä»¶ç‰ˆæœ¬ï¼š** v1.0
**æœ€å¾Œæ›´æ–°ï¼š** 2025/11/16
