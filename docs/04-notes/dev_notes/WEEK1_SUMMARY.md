# Week 1 完成總結 & Week 2-3 預告

**日期：** 2025/11/21～11/27
**目標：** 環境驗證 + SLAM/Nav2 基礎確認
**Demo 日期倒計時：** 26 天（12/17）

---

## ✅ Week 1 交付清單

### 已完成文件（本週生成）

| 文件 | 位置 | 用途 | 狀態 |
|------|------|------|------|
| **Mac M1 + UTM 虛擬機部署指南** | `docs/01-guides/mac_utm_vm_setup.md` | 3000 字詳細教程 | ✅ |
| **Phase 1 快速驗證清單** | `docs/01-guides/phase1_quick_check.md` | 7 項檢查 3-5 分鐘 | ✅ |
| **模擬器環境確認清單** | `docs/01-guides/simulator_setup_checklist.md` | 與柏翊同步進度 | ✅ |
| **測試日誌範本** | `docs/04-notes/dev_notes/20251121_slam_test.md` | Phase 1 & 2 測試記錄 | ✅ |
| **完整測試指南** | `docs/04-notes/dev_notes/PHASE1_EXECUTION_GUIDE.md` | 詳細步驟 + 故障排查 | ✅ |

### 你需要在 Week 1 完成的（11/21～11/27）

**優先級 1（必做）：**
- [ ] 完成當前 Linux 機器的 **Phase 1 測試**（2-3 小時）
  - 檢查清單：7 項全通過
  - 填寫 20251121_slam_test.md Phase 1 部分

- [ ] 在 Mac 上安裝並配置 **UTM 虛擬機**（3-4 小時）
  - 按照 mac_utm_vm_setup.md 逐步執行
  - 重點：**網路橋接配置**（這是連接 Go2 Wi-Fi 的關鍵）
  - 安裝 ROS2 Humble + 本專案環境

- [ ] 在虛擬機中執行 **Phase 1 快速驗證**（30 分鐘）
  - 按照 phase1_quick_check.md 驗證 7 項
  - 記錄 /scan 和 /map 的頻率

**優先級 2（建議）：**
- [ ] 與柏翊確認 **模擬器部署進度**
  - Isaac Sim 是否已下載
  - go2_omniverse 是否可運行
  - 預計 11/26 前 Phase 0 完成

---

## 🎯 Week 1 成功標誌

**全部完成表示你已準備好開始 Week 2 開發：**

```
✅ Linux 機器 Phase 1：7/7 檢查項通過
✅ UTM 虛擬機：網路橋接可用，能 ping 192.168.12.1
✅ 虛擬機 Phase 1：7/7 檢查項通過
✅ 模擬器清點：確認與 Isaac Sim 的同步進度
```

---

## 📅 Week 2 開發計畫（11/28～12/04）

### 平行開發兩個核心模組

**模組 A：COCO 物體偵測節點**
```
目標：vision_vlm/coco_detector.py 完成
輸入：/camera/image_raw (影像 topic)
輸出：Detection2DArray (bbox + 物體類別)
性能：GPU 上 > 10 FPS（或 1-2 Hz）

交付物：
- ✅ coco_detector.py（可執行）
- ✅ launch 檔案
- ✅ 實作指南（2000 字）
- ✅ 在虛擬機上驗證通過
```

**模組 B：座標轉換節點**
```
目標：vision_vlm/image_to_3d.py 完成
輸入：2D bbox + camera_info + LiDAR point_cloud
輸出：PoseStamped (3D 世界座標，map frame)
精度：距離誤差 < 50cm

交付物：
- ✅ image_to_3d.py（可執行）
- ✅ tf2 轉換邏輯
- ✅ 實作指南（2500 字）
- ✅ 精度驗證測試

關鍵：LiDAR 點雲投影 + tf2 坐標轉換
```

### Week 2 文件交付（週五 12/03 前）

1. **「COCO 物體偵測實現指南」** (2000 字 + 代碼)
   - PyTorch 推論框架
   - topic 訂閱/發佈樣板
   - 參數調整（信心、NMS、FPS）
   - 虛擬機驗證步驟

2. **「LiDAR 座標轉換實現指南」** (2500 字 + 代碼)
   - 深度影像投影原理
   - tf2 使用教學
   - 誤差分析和多點平均
   - 完整範例

3. **「vision_vlm 套件框架」** (可執行代碼)
   - package.xml / setup.py
   - launch 檔案
   - 示例節點

---

## 📅 Week 3 衝刺計畫（12/05～12/12）

### 尋物 FSM 實現（核心邏輯）

```
狀態機四大狀態：

IDLE (等待指令)
  ↓
PATROL (自動巡邏 - 用 Nav2 預設路點)
  ↓
SCAN (靜止掃描 - COCO 推論，蒐集視野物體)
  ↓
NAVIGATE (自動導航 - 座標轉換結果 → Nav2 目標)
  ↓
SUCCESS (找到物體，停止)
```

### 交付物（12/09 前）

1. **尋物 FSM 完整設計** (3000 字)
   - 狀態機圖（Mermaid）
   - 轉換條件詳細定義
   - topic interface 清單
   - 完整代碼

2. **Web 視覺化**
   - Foxglove 面板或簡單 Python GUI
   - 顯示：相機、地圖、搜尋狀態
   - 指令輸入：物體名稱

3. **Demo 腳本**
   - run_full_demo.sh（一鍵啟動）
   - 故障快速修復清單
   - 預錄演示影片

4. **更新 conformance_check_plan.md**
   - 補充 Week 6-9 技術細節
   - 實機 + 模擬器雙環境驗證

---

## 🎬 Demo 最終準備（12/13～12/17）

### 實機環節（5 分鐘）
```
1. 虛擬機內啟動 SLAM + Nav2
2. 發送搜尋指令（「找眼鏡」）
3. 機器狗自動：巡邏 → 掃描 → 導航 → 停止
4. RViz 或 Web 顯示搜尋結果
```

### 模擬器環節（5 分鐘）
```
1. Isaac Sim 中啟動 go2_omniverse
2. 同樣搜尋指令
3. 展示完整端到端流程（無 Wi-Fi 延遲，最穩定）
4. 對比實機和模擬器的差異
```

### 備案方案
- 提前錄製完整流程影片（如現場故障可播放）
- 製作簡化版 Demo（只展示某個環節）
- 文件和架構圖作為技術展示

---

## 📊 時間表（每日檢查點）

```
Week 1 (11/21～11/27)
  ├─ 11/21～11/24：完成 Phase 1 測試（Linux + UTM VM）
  ├─ 11/25～11/26：模擬器環境清點
  └─ 11/27：文檔完成 + Week 2 代碼框架準備

Week 2 (11/28～12/04)
  ├─ 11/28～12/01：COCO 節點開發完成
  ├─ 12/01～12/03：座標轉換開發完成
  ├─ 12/03：兩模組整合測試通過
  └─ 12/04：Week 2 文檔交付

Week 3 (12/05～12/12)
  ├─ 12/05～12/08：FSM 開發 + 集成測試
  ├─ 12/08～12/10：Web 視覺化 + Demo 腳本
  ├─ 12/10：文件凍結（12/12 繳交）
  └─ 12/11：內部審查和修正

Demo 準備 (12/13～12/17)
  ├─ 12/13～12/15：實機和模擬器預演
  ├─ 12/15：備案影片錄製
  └─ 12/17：正式展示
```

---

## 🚦 風險與對策

| 風險 | 等級 | 發生機率 | 對策 |
|------|------|--------|------|
| **虛擬機網路橋接失敗** | 🔴 高 | 30% | 提供詳細教程 + 遠端支援 |
| **COCO 推論速度不夠** | 🟡 中 | 20% | 提前測試，備用輕量模型 |
| **座標轉換精度不足** | 🟡 中 | 25% | 多點平均或 ICP 算法 |
| **Isaac Sim 延遲** | 🟡 中 | 15% | 預錄影片或改用本地 VM |
| **Demo 時間超時** | 🟡 中 | 20% | 準備 3 個版本（完整/快速/影片） |

---

## 📝 記錄與回顧

**請在本週末填寫：**

```markdown
# Week 1 實驗報告（11/21～11/27）

## 完成項目
- [ ] Phase 1 Linux 測試：___/7 項通過
- [ ] UTM 虛擬機部署：✅ / ⚠️ / ❌
- [ ] Phase 1 虛擬機驗證：___/7 項通過
- [ ] 模擬器清點完成：✅ / ⚠️ / ❌

## 遇到的問題
1. ___
2. ___

## 次週預備
- [ ] 閱讀 COCO 實現指南
- [ ] 準備開發環境（IDE、GPU 存取等）
- [ ] 確認座標轉換的 LiDAR 數據源

## 反饋與建議
___
```

---

## 🎯 成功條件

**Week 1 評分標準：**

| 項目 | 滿分 | 你的分數 |
|------|------|--------|
| Phase 1 Linux 驗證 | 20 | ___ |
| UTM 虛擬機部署 | 20 | ___ |
| Phase 1 虛擬機驗證 | 20 | ___ |
| 模擬器清點完成 | 20 | ___ |
| 文檔閱讀與理解 | 20 | ___ |
| **合計** | **100** | **___** |

**及格線：60 分（可開始 Week 2 開發）**

---

## 💡 Week 2 提前準備

**即使 Week 1 未完全完成，也可提前準備 Week 2：**

```bash
# 1. 克隆 COCO 相關代碼
git clone https://github.com/ultralytics/yolov5  # 或 MobileNet
cd yolov5
pip install -r requirements.txt

# 2. 下載 COCO 預訓練權重
python -m yolov5 classify --model yolov5n-cls.pt --source data/images

# 3. 研究 tf2 坐標轉換
rosdep install tf2-geometry-msgs
ros2 pkg list | grep tf2
```

---

## 📞 聯繫方式

有任何 Week 1 的問題：
- 🔴 **重大阻礙** → 立刻聯繫（不要等）
- 🟡 **小問題** → 記錄在本文檔，周末整理
- 📋 **文檔錯誤** → GitHub Issue 或群組通知

---

## 🚀 展望

**如果 Week 1-3 全部順利完成，12/17 Demo 你將展示：**

```
✨ 完整智慧尋物系統 ✨

輸入：「找眼鏡」
過程：SLAM 建圖 → Nav2 導航 → COCO 偵測 → 座標轉換 → 自動導航
輸出：機器狗走到眼鏡位置，Web 顯示「FOUND!」

在實機和模擬器上都能成功執行。
```

**加油！26 天後見！** 💪

---

**最後提醒：** 不要焦慮。按部就班，一個 Week 一個 Week 完成。若有困難，提早回報，我們一起解決。

